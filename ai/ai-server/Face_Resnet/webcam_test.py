# webcam_test.py (ì „ì²´ ìˆ˜ì •ë³¸)

import cv2
import torch
from PIL import Image
import json
from datetime import datetime
from collections import Counter
from transformers import ResNetForImageClassification, ResNetConfig, AutoImageProcessor
import os

# FER-2013 ê°ì • ë ˆì´ë¸”
CLASS_NAMES = ["anger", "disgust", "fear", "happy", "sad", "surprise", "neutral"]

# ğŸ’¡ Hugging Faceì—ì„œ ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ê¸°ë¥¼ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
try:
    # ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    model_name = "Celal11/resnet-50-finetuned-FER2013-0.001"
    model = ResNetForImageClassification.from_pretrained(model_name)
    
    # ğŸ’¡ ì „ì²˜ë¦¬ê¸°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ì‹ì„ 'AutoImageProcessor'ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
    processor = AutoImageProcessor.from_pretrained(model_name)
    print("ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ê¸°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
except Exception as e:
    print(f"ì˜¤ë¥˜: ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. {e}")
    print("ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜, transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit()

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()

# ì›¹ìº  ì„¤ì •
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

all_frames_emotions = []
detailed_logs = []
current_emotion = None
start_frame = None
frame_count = 0

print("ì›¹ìº ì„ ì‹œì‘í•©ë‹ˆë‹¤. 'q'ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.")

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # ì¢Œìš° ë°˜ì „
    frame = cv2.flip(frame, 1)

    frame_count += 1
    
    pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    
    # Hugging Face ì „ì²˜ë¦¬ê¸°ë¡œ ì´ë¯¸ì§€ ë³€í™˜
    inputs = processor(images=pil_image, return_tensors="pt")
    inputs = {key: value.to(device) for key, value in inputs.items()}

    predicted_emotion = "ë¶ˆí™•ì‹¤"
    top_emotions = []

    with torch.no_grad():
        outputs = model(**inputs)
        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)[0]
        
        # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ ê°ì • 3ê°€ì§€ ì¶”ì¶œ
        top_probs, top_indices = torch.topk(probabilities, 3)
        
        for prob, idx in zip(top_probs, top_indices):
            emotion = model.config.id2label[idx.item()]
            top_emotions.append((emotion, prob.item()))
            
        main_emotion_idx = top_indices[0].item()
        main_emotion_prob = top_probs[0].item()

        if main_emotion_prob > 0.2:
            predicted_emotion = model.config.id2label[main_emotion_idx]
        else:
            predicted_emotion = "ë¶ˆí™•ì‹¤"

    all_frames_emotions.append(predicted_emotion)
    
    if current_emotion is None:
        current_emotion = predicted_emotion
        start_frame = frame_count
    elif predicted_emotion != current_emotion:
        end_frame = frame_count - 1
        detailed_logs.append({
            "label": current_emotion,
            "start_frame": start_frame,
            "end_frame": end_frame
        })
        current_emotion = predicted_emotion
        start_frame = frame_count
    
    y_offset = 50
    for i, (emotion, prob) in enumerate(top_emotions):
        text = f"{emotion}: {prob:.2f}"
        cv2.putText(frame, text, (50, y_offset + i * 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)

    cv2.imshow('Emotion Recognition', frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        if current_emotion:
            end_frame = frame_count
            detailed_logs.append({
                "label": current_emotion,
                "start_frame": start_frame,
                "end_frame": end_frame
            })
        break

cap.release()
cv2.destroyAllWindows()

if frame_count > 0:
    emotion_counts = Counter(all_frames_emotions)
    frame_distribution = {}
    for emotion, count in emotion_counts.items():
        frame_distribution[emotion] = count

    report = {
        "timestamp": datetime.now().isoformat(),
        "total_frames": frame_count,
        "frame_distribution": frame_distribution,
        "detailed_logs": detailed_logs
    }

    report_filename = "emotion_report.json"
    with open(report_filename, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=4)
        
    print(f"ê°ì • ë³€í™” ë¦¬í¬íŠ¸ê°€ '{report_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
else:
    print("ê°ì§€ëœ í”„ë ˆì„ì´ ì—†ì–´ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")